name: Full Pickleball Schedule Scraper

on:
  workflow_dispatch:
  schedule:
    # Run every Sunday at 1:00 AM UTC
    - cron: '0 1 * * 0'

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Create package.json
        run: |
          cat > package.json << 'EOF'
          {
            "name": "lifetime-scraper",
            "version": "1.0.0",
            "description": "Weekly scraper for Lifetime Pickleball schedule",
            "main": "scraper.js",
            "type": "module",
            "scripts": {
              "start": "node scraper.js"
            },
            "dependencies": {
              "puppeteer-core": "^21.0.0",
              "@sparticuz/chromium": "^121.0.0",
              "node-fetch": "^3.3.1"
            }
          }
          EOF

      - name: Create scraper.js
        run: |
          cat > scraper.js << 'EOF'
          import puppeteer from 'puppeteer-core';
          import chromium from '@sparticuz/chromium';
          import fs from 'fs';
          import { mkdir } from 'fs/promises';

          async function scrapeLifetimeSchedule() {
            console.log("Starting scheduled Lifetime schedule scrape...");
            console.log("Server time: " + new Date().toISOString());

            let browser = null;

            try {
              const username = process.env.LIFETIME_USERNAME;
              const password = process.env.LIFETIME_PASSWORD;

              if (!username || !password) {
                throw new Error("Missing Lifetime credentials in environment variables");
              }

              // Set nextSunday to exactly 7 days from today
              const today = new Date();
              const nextSunday = new Date(today);
              nextSunday.setDate(today.getDate() + 7);

              console.log("Today is " + today.toDateString() + ", next Sunday is " + nextSunday.toDateString());

              const weekdays = ["SUNDAY", "MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY", "SATURDAY"];

              const scheduleData = {
                month: nextSunday.toLocaleString("default", { month: "long" }).toUpperCase(),
                days: [],
                _source: "github-actions-scraper",
                _debug: {
                  serverTime: today.toISOString(),
                  calculatedNextSunday: nextSunday.toISOString(),
                },
              };

              // Initialize map for 7 days
              const dayMap = new Map();
              for (let i = 0; i < 7; i++) {
                const sessionDate = new Date(nextSunday);
                sessionDate.setDate(nextSunday.getDate() + i);

                const dayName = weekdays[i];
                const date = sessionDate.getDate();
                const dayKey = dayName + "-" + date;

                dayMap.set(dayKey, {
                  name: dayName,
                  date: date,
                  highlight: false,
                  sessions: [],
                  header: dayName + " " + date,
                });
              }

              browser = await puppeteer.launch({
                args: [
                  ...chromium.args,
                  "--disable-dev-shm-usage",
                  "--disable-gpu",
                  "--single-process",
                  "--no-zygote",
                  "--no-sandbox",
                  "--disable-setuid-sandbox",
                ],
                defaultViewport: {
                  width: 1024,
                  height: 768,
                  deviceScaleFactor: 1,
                },
                executablePath: await chromium.executablePath(),
                headless: true,
                ignoreHTTPSErrors: true,
              });

              const page = await browser.newPage();
              await page.setUserAgent(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
              );
              await page.setCacheEnabled(false);
              await page.setRequestInterception(true);
              page.on('request', (req) => {
                const resourceType = req.resourceType();
                if (['image', 'font', 'media'].includes(resourceType)) {
                  req.abort();
                } else {
                  req.continue();
                }
              });

              await page.goto("https://my.lifetime.life/login.html", {
                waitUntil: "domcontentloaded",
                timeout: 30000,
              });

              await page.waitForSelector('input[type="email"], #username, input[name="username"]', { timeout: 10000 });
              await page.type('input[type="email"], #username, input[name="username"]', username);
              await page.type('input[type="password"], #password', password);
              await Promise.all([
                page.waitForNavigation({ waitUntil: "domcontentloaded", timeout: 30000 }),
                page.click('button[type="submit"], input[type="submit"]'),
              ]);

              const year = nextSunday.getFullYear();
              const month = String(nextSunday.getMonth() + 1).padStart(2, "0");
              const day = String(nextSunday.getDate()).padStart(2, "0");
              const formattedDate = year + "-" + month + "-" + day;

              const weekViewUrl = "https://my.lifetime.life/clubs/ny/penn-1/classes.html?teamMemberView=true&mode=week&selectedDate=" + formattedDate + "&interest=Pickleball+Open+Play&location=PENN+1";
              console.log("Navigating to week view: " + weekViewUrl);

              await page.goto(weekViewUrl, {
                waitUntil: "domcontentloaded",
                timeout: 30000,
              });

              await page.waitForSelector(".planner-entry, .planner-row", { visible: true, timeout: 15000 });
              await page.waitForTimeout(3000);

              // TODO: Insert page.evaluate() scraping logic here

              if (!fs.existsSync('./data')) {
                await mkdir('./data', { recursive: true });
              }

              fs.writeFileSync('./data/schedule.json', JSON.stringify(scheduleData, null, 2));
              console.log("Saved schedule data to ./data/schedule.json");
            } catch (error) {
              console.error("Error in scrapeLifetimeSchedule:", error);
              throw error;
            } finally {
              if (browser) {
                await browser.close();
                console.log("Browser closed");
              }
            }
          }

          scrapeLifetimeSchedule()
            .then(() => {
              console.log('Scraper completed successfully');
              process.exit(0);
            })
            .catch((error) => {
              console.error('Scraper failed:', error);
              process.exit(1);
            });
          EOF

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        env:
          LIFETIME_USERNAME: ${{ secrets.LIFETIME_USERNAME }}
          LIFETIME_PASSWORD: ${{ secrets.LIFETIME_PASSWORD }}
        run: node scraper.js

      - name: Commit and push data
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add data/schedule.json
          git commit -m "Update schedule data [skip ci]"
          git pull --rebase origin main
          git push
