name: Full Pickleball Schedule Scraper

on:
  workflow_dispatch:
  schedule:
    # Run every Sunday at 1:00 AM UTC
    - cron: '0 1 * * 0'

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Create package.json
        run: |
          cat > package.json << 'EOF'
          {
            "name": "lifetime-scraper",
            "version": "1.0.0",
            "description": "Weekly scraper for Lifetime Pickleball schedule",
            "main": "scraper.js",
            "type": "module",
            "scripts": {
              "start": "node scraper.js"
            },
            "dependencies": {
              "puppeteer-core": "^21.0.0",
              "@sparticuz/chromium": "^121.0.0",
              "node-fetch": "^3.3.1"
            }
          }
          EOF

      - name: Create scraper.js
        run: |
          cat > scraper.js << 'EOF'
          import puppeteer from 'puppeteer-core';
          import chromium from '@sparticuz/chromium';
          import fs from 'fs';
          import { mkdir } from 'fs/promises';
          import fetch from 'node-fetch';

          async function scrapeLifetimeSchedule() {
            console.log("Starting scheduled Lifetime schedule scrape...");
            console.log("Server time: " + new Date().toISOString());

            let browser = null;

            try {
              const username = process.env.LIFETIME_USERNAME;
              const password = process.env.LIFETIME_PASSWORD;
              if (!username || !password) throw new Error("Missing Lifetime credentials");

              const today = new Date();
              const nextSunday = new Date(today);
              const daysUntilNextSunday = today.getDay() === 0 ? 7 : 7 - today.getDay();
              nextSunday.setDate(today.getDate() + daysUntilNextSunday);
              console.log("Today is " + today.toDateString() + ", next Sunday is " + nextSunday.toDateString());

              const weekdays = ["SUNDAY", "MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY", "SATURDAY"];
              const scheduleData = {
                month: nextSunday.toLocaleString("default", { month: "long" }).toUpperCase(),
                days: [],
                _source: "github-actions-scraper",
                _debug: {
                  serverTime: today.toISOString(),
                  calculatedNextSunday: nextSunday.toISOString(),
                  daysUntilNextSunday
                }
              };

              const dayMap = new Map();
              for (let i = 0; i < 7; i++) {
                const sessionDate = new Date(nextSunday);
                sessionDate.setDate(nextSunday.getDate() + i);
                const dayName = weekdays[i];
                const date = sessionDate.getDate();
                const dayKey = `${dayName}-${date}`;
                dayMap.set(dayKey, {
                  name: dayName,
                  date: date,
                  highlight: false,
                  sessions: [],
                  header: `${dayName} ${date}`
                });
              }

              console.log("Launching browser...");
              browser = await puppeteer.launch({
                args: [
                  ...chromium.args,
                  "--disable-dev-shm-usage",
                  "--disable-gpu",
                  "--single-process",
                  "--no-zygote",
                  "--no-sandbox",
                  "--disable-setuid-sandbox"
                ],
                defaultViewport: {
                  width: 1024,
                  height: 768,
                  deviceScaleFactor: 1
                },
                executablePath: await chromium.executablePath(),
                headless: true,
                ignoreHTTPSErrors: true
              });

              const page = await browser.newPage();
              await page.setUserAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36");
              await page.setCacheEnabled(false);
              await page.setRequestInterception(true);
              page.on('request', req => {
                const resourceType = req.resourceType();
                if (['image', 'font', 'media'].includes(resourceType)) {
                  req.abort();
                } else {
                  req.continue();
                }
              });

              console.log("Navigating to login page...");
              await page.goto("https://my.lifetime.life/login.html", { waitUntil: "domcontentloaded", timeout: 30000 });
              await page.waitForSelector('input[type="email"], #username, input[name="username"]', { timeout: 10000 });
              await page.type('input[type="email"], #username, input[name="username"]', username);
              await page.type('input[type="password"], #password', password);
              await Promise.all([
                page.waitForNavigation({ waitUntil: "domcontentloaded", timeout: 30000 }),
                page.click('button[type="submit"], input[type="submit"]')
              ]);

              const year = nextSunday.getFullYear();
              const month = String(nextSunday.getMonth() + 1).padStart(2, "0");
              const day = String(nextSunday.getDate()).padStart(2, "0");
              const formattedDate = `${year}-${month}-${day}`;
              const weekViewUrl = `https://my.lifetime.life/clubs/ny/penn-1/classes.html?teamMemberView=true&mode=week&selectedDate=${formattedDate}&interest=Pickleball+Open+Play&location=PENN+1`;

              console.log("Navigating to week view: " + weekViewUrl);
              await page.goto(weekViewUrl, { waitUntil: "domcontentloaded", timeout: 30000 });
              await page.waitForSelector(".planner-entry, .planner-row", { visible: true, timeout: 15000 });
              await page.waitForTimeout(3000);

              // Your existing page.evaluate scraping logic goes here

              // Just simulating dummy session data for the moment
              const dummySessions = Array.from(dayMap.values()).map((day, index) => ({
                ...day,
                sessions: [{ id: `session-${index}`, title: "Sample Session", startTime: "10:00 AM", endTime: "11:30 AM" }]
              }));

              // Replace with real extraction result:
              scheduleData.days = dummySessions;

              // ðŸ§  FIXED: Chronological weekday sorting (even across months)
              scheduleData.days.sort((a, b) => {
                const getDateObj = (day) => {
                  const index = weekdays.indexOf(day.name);
                  const base = new Date(nextSunday);
                  base.setDate(nextSunday.getDate() + index);
                  return base;
                };
                return getDateObj(a) - getDateObj(b);
              });

              if (!fs.existsSync('./data')) {
                await mkdir('./data', { recursive: true });
              }

              const outputPath = './data/schedule.json';
              fs.writeFileSync(outputPath, JSON.stringify(scheduleData, null, 2));
              console.log("Saved schedule data to " + outputPath);

              return scheduleData;
            } catch (error) {
              console.error("Error in scrapeLifetimeSchedule:", error);
              throw error;
            } finally {
              if (browser) {
                await browser.close();
                console.log("Browser closed");
              }
            }
          }

          scrapeLifetimeSchedule()
            .then(() => {
              console.log("Scraper completed successfully");
              process.exit(0);
            })
            .catch((error) => {
              console.error("Scraper failed:", error);
              process.exit(1);
            });
          EOF

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        env:
          LIFETIME_USERNAME: ${{ secrets.LIFETIME_USERNAME }}
          LIFETIME_PASSWORD: ${{ secrets.LIFETIME_PASSWORD }}
        run: node scraper.js

      - name: Commit and push data
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add data/schedule.json
          git commit -m "Update schedule data [skip ci]"
          git pull --rebase origin main
          git push
